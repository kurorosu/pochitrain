#!/usr/bin/env python3
"""
pochitrain çµ±ä¸€CLI ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ.

è¨“ç·´ã¨æ¨è«–ã‚’çµ±åˆã—ãŸã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import argparse
import importlib.util
import sys
from pathlib import Path

from torch.utils.data import DataLoader

from pochitrain import (
    LoggerManager,
    PochiImageDataset,
    PochiPredictor,
    PochiTrainer,
    create_data_loaders,
)
from pochitrain.validation import ConfigValidator


def setup_logging(logger_name: str = "pochitrain"):
    """
    ãƒ­ã‚°è¨­å®šã®åˆæœŸåŒ–.

    Args:
        logger_name (str): ãƒ­ã‚¬ãƒ¼å

    Returns:
        logger: è¨­å®šæ¸ˆã¿ãƒ­ã‚¬ãƒ¼
    """
    logger_manager = LoggerManager()
    return logger_manager.get_logger(logger_name)


def load_config(config_path: str) -> dict:
    """
    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€.

    Args:
        config_path (str): è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        dict: è¨­å®šè¾æ›¸
    """
    config_path_obj = Path(config_path)

    if not config_path_obj.exists():
        raise FileNotFoundError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

    # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦èª­ã¿è¾¼ã¿
    spec = importlib.util.spec_from_file_location("config", config_path_obj)
    if spec is None:
        raise RuntimeError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {config_path}")

    config_module = importlib.util.module_from_spec(spec)
    if spec.loader is None:
        raise RuntimeError(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {config_path}")

    spec.loader.exec_module(config_module)

    # è¨­å®šè¾æ›¸ã‚’æ§‹ç¯‰
    config = {}
    for key in dir(config_module):
        if not key.startswith("_"):
            value = getattr(config_module, key)
            # é–¢æ•°ã‚„ãƒ¡ã‚½ãƒƒãƒ‰ã¯é™¤å¤–ã™ã‚‹ãŒã€transformsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯å«ã‚ã‚‹
            if not callable(value) or hasattr(value, "transforms"):
                config[key] = value

    return config


def find_best_model(work_dir: str) -> Path:
    """
    work_dirå†…ã§ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•æ¤œå‡º.

    Args:
        work_dir (str): ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹

    Returns:
        Path: ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    """
    work_path = Path(work_dir)
    models_dir = work_path / "models"

    if not models_dir.exists():
        raise FileNotFoundError(f"ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {models_dir}")

    # best_epoch*.pth ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    model_files = list(models_dir.glob("best_epoch*.pth"))

    if not model_files:
        raise FileNotFoundError(
            f"ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {models_dir}/best_epoch*.pth"
        )

    # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆã‚¨ãƒãƒƒã‚¯ç•ªå·ãŒæœ€å¤§ã®ã‚‚ã®ï¼‰
    best_model = max(model_files, key=lambda x: x.name)
    return best_model


def validate_config(config: dict, logger) -> bool:
    """
    è¨­å®šã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³.

    Args:
        config (dict): è¨­å®šè¾æ›¸
        logger: ãƒ­ã‚¬ãƒ¼

    Returns:
        bool: ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³çµæœ
    """
    validator = ConfigValidator(logger)
    return validator.validate(config)


def train_command(args):
    """è¨“ç·´ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ."""
    logger = setup_logging()
    logger.info("=== pochitrain è¨“ç·´ãƒ¢ãƒ¼ãƒ‰ ===")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    try:
        config = load_config(args.config)
        logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {args.config}")
    except FileNotFoundError:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.config}")
        logger.error("configs/pochi_train_config.py ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
        return

    # è¨­å®šã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    if not validate_config(config, logger):
        logger.error("è¨­å®šã«ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Šã¾ã™ã€‚ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
        return

    # è¨­å®šç¢ºèªãƒ­ã‚°
    logger.info("=== è¨­å®šç¢ºèª ===")
    logger.info(f"ãƒ¢ãƒ‡ãƒ«: {config['model_name']}")
    logger.info(f"ãƒ‡ãƒã‚¤ã‚¹: {config['device']}")
    logger.info(f"å­¦ç¿’ç‡: {config['learning_rate']}")
    logger.info(f"ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼: {config['optimizer']}")

    # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®šã®æ˜ç¤ºçš„ãƒ­ã‚°å‡ºåŠ›
    scheduler_name = config.get("scheduler")
    if scheduler_name is None:
        logger.info("ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼: ãªã—ï¼ˆå›ºå®šå­¦ç¿’ç‡ï¼‰")
    else:
        logger.info(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼: {scheduler_name}")
        scheduler_params = config.get("scheduler_params")
        logger.info(f"ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {scheduler_params}")

    # ã‚¯ãƒ©ã‚¹é‡ã¿è¨­å®šã®æ˜ç¤ºçš„ãƒ­ã‚°å‡ºåŠ›
    class_weights = config.get("class_weights")
    if class_weights is None:
        logger.info("ã‚¯ãƒ©ã‚¹é‡ã¿: ãªã—ï¼ˆå‡ç­‰æ‰±ã„ï¼‰")
    else:
        logger.info(f"ã‚¯ãƒ©ã‚¹é‡ã¿: {class_weights}")

    logger.info("==================")

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆ
    logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
    try:
        train_loader, val_loader, classes = create_data_loaders(
            train_root=config["train_data_root"],
            val_root=config["val_data_root"],
            batch_size=config["batch_size"],
            num_workers=config["num_workers"],
            train_transform=config.get("train_transform"),
            val_transform=config.get("val_transform"),
        )

        logger.info(f"ã‚¯ãƒ©ã‚¹æ•°: {len(classes)}")
        logger.info(f"ã‚¯ãƒ©ã‚¹å: {classes}")
        logger.info(f"è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}")
        logger.info(f"æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}")

        # è¨­å®šã®ã‚¯ãƒ©ã‚¹æ•°ã‚’æ›´æ–°
        config["num_classes"] = len(classes)

    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®ä½œæˆ
    logger.info("ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
    trainer = PochiTrainer(
        model_name=config["model_name"],
        num_classes=config["num_classes"],
        device=config["device"],
        pretrained=config["pretrained"],
        work_dir=config["work_dir"],
    )

    # è¨“ç·´è¨­å®š
    logger.info("è¨“ç·´è¨­å®šã‚’è¡Œã£ã¦ã„ã¾ã™...")
    trainer.setup_training(
        learning_rate=config["learning_rate"],
        optimizer_name=config["optimizer"],
        scheduler_name=config.get("scheduler"),
        scheduler_params=config.get("scheduler_params"),
        class_weights=config.get("class_weights"),
        num_classes=len(classes),
    )

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ã®ä¿å­˜
    logger.info("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™...")
    trainer.save_dataset_paths(train_loader, val_loader)

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜
    logger.info("è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™...")
    config_path_obj = Path(args.config)
    saved_config_path = trainer.save_training_config(config_path_obj)
    logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {saved_config_path}")

    # è¨“ç·´å®Ÿè¡Œ
    logger.info("è¨“ç·´ã‚’é–‹å§‹ã—ã¾ã™...")
    trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=config["epochs"],
    )

    logger.info("è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    logger.info(f"çµæœã¯ {config['work_dir']} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™ã€‚")


def infer_command(args):
    """æ¨è«–ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œ."""
    logger = setup_logging()
    logger.info("=== pochitrain æ¨è«–ãƒ¢ãƒ¼ãƒ‰ ===")

    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    config_path = Path(args.config_path)
    try:
        config = load_config(str(config_path))
        logger.info(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿: {config_path}")
    except Exception as e:
        logger.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(
            f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {args.config_path}"
        )
        return

    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ç¢ºèª
    model_path = Path(args.model_path)
    if not model_path.exists():
        logger.error(f"æŒ‡å®šã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
        return
    logger.info(f"ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«: {model_path}")

    # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª
    data_root = args.data
    if not Path(data_root).exists():
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_root}")
        return
    logger.info(f"æ¨è«–ãƒ‡ãƒ¼ã‚¿: {data_root}")

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®æ±ºå®šï¼ˆãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
    if args.output:
        output_dir = args.output
    else:
        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«å‡ºåŠ›
        model_dir = model_path.parent
        output_dir = str(model_dir / "inference_results")

    logger.info(f"æ¨è«–çµæœå‡ºåŠ›å…ˆ: {output_dir}")

    # æ¨è«–å™¨ä½œæˆ
    logger.info("æ¨è«–å™¨ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
    try:
        predictor = PochiPredictor(
            model_name=config["model_name"],
            num_classes=config["num_classes"],
            device=config["device"],
            model_path=str(model_path),
            work_dir=output_dir,
        )
        logger.info("âœ… æ¨è«–å™¨ã®ä½œæˆæˆåŠŸ")
    except Exception as e:
        logger.error(f"æ¨è«–å™¨ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return

    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆï¼ˆè¨“ç·´æ™‚ã¨åŒã˜val_transformã‚’ä½¿ç”¨ï¼‰
    logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
    try:
        val_dataset = PochiImageDataset(data_root, transform=config["val_transform"])
        val_loader = DataLoader(
            val_dataset,
            batch_size=config["batch_size"],
            shuffle=False,
            num_workers=config.get("num_workers", 0),
            pin_memory=True,
        )

        logger.info(f"ğŸ“Š æ¨è«–ãƒ‡ãƒ¼ã‚¿: {len(val_dataset)}æšã®ç”»åƒ")
        logger.info("ğŸ“‹ ä½¿ç”¨ã•ã‚ŒãŸTransform (è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰):")
        for i, transform in enumerate(config["val_transform"].transforms):
            logger.info(f"   {i+1}. {transform}")

    except Exception as e:
        logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
        return

    # æ¨è«–å®Ÿè¡Œ
    logger.info("æ¨è«–ã‚’é–‹å§‹ã—ã¾ã™...")
    try:
        predictions, confidences = predictor.predict(val_loader)

        # çµæœæ•´ç†
        image_paths = val_dataset.get_file_paths()
        predicted_labels = predictions.tolist()
        confidence_scores = confidences.tolist()
        true_labels = val_dataset.labels
        class_names = val_dataset.get_classes()

        logger.info("âœ… æ¨è«–å®Œäº†")

    except Exception as e:
        logger.error(f"æ¨è«–å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return

    # CSVå‡ºåŠ›
    logger.info("çµæœã‚’CSVã«å‡ºåŠ›ã—ã¦ã„ã¾ã™...")
    try:
        results_csv, summary_csv = predictor.export_results_to_workspace(
            image_paths=image_paths,
            predicted_labels=predicted_labels,
            true_labels=true_labels,
            confidence_scores=confidence_scores,
            class_names=class_names,
            results_filename="inference_results.csv",
            summary_filename="inference_summary.csv",
        )

        # ç²¾åº¦è¨ˆç®—ãƒ»è¡¨ç¤º
        accuracy_info = predictor.calculate_accuracy(predicted_labels, true_labels)

        logger.info("=== æ¨è«–çµæœ ===")
        logger.info(f"å‡¦ç†ç”»åƒæ•°: {accuracy_info['total_samples']}æš")
        logger.info(f"æ­£è§£æ•°: {accuracy_info['correct_predictions']}")
        logger.info(f"ç²¾åº¦: {accuracy_info['accuracy_percentage']:.2f}%")
        logger.info(f"è©³ç´°çµæœ: {results_csv}")
        logger.info(f"ã‚µãƒãƒªãƒ¼: {summary_csv}")

        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹æƒ…å ±
        workspace_info = predictor.get_inference_workspace_info()
        logger.info(f"ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹: {workspace_info['workspace_name']}")

        logger.info("æ¨è«–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    except Exception as e:
        logger.error(f"CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
        return


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°."""
    parser = argparse.ArgumentParser(
        description="pochitrain - çµ±åˆCLIï¼ˆè¨“ç·´ãƒ»æ¨è«–ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  # è¨“ç·´
  python pochi.py train
    --config configs/pochi_train_config.py

  # æ¨è«–ï¼ˆåŸºæœ¬ï¼‰
  python pochi.py infer
    -m work_dirs/20250813_003/models/best_epoch40.pth
    -d data/val
    -c work_dirs/20250813_003/config.py

  # æ¨è«–ï¼ˆã‚«ã‚¹ã‚¿ãƒ å‡ºåŠ›å…ˆï¼‰
  python pochi.py infer
    --model-path work_dirs/20250813_003/models/best_epoch40.pth
    --data data/test
    --config-path work_dirs/20250813_003/config.py
    --output custom_results
        """,
    )

    subparsers = parser.add_subparsers(dest="command", help="ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰")

    # è¨“ç·´ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    train_parser = subparsers.add_parser("train", help="ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
    train_parser.add_argument(
        "--config",
        default="configs/pochi_train_config.py",
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (default: configs/pochi_train_config.py)",
    )

    # æ¨è«–ã‚µãƒ–ã‚³ãƒãƒ³ãƒ‰
    infer_parser = subparsers.add_parser("infer", help="ãƒ¢ãƒ‡ãƒ«æ¨è«–")
    infer_parser.add_argument(
        "--model-path", "-m", required=True, help="ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"
    )
    infer_parser.add_argument("--data", "-d", required=True, help="æ¨è«–ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹")
    infer_parser.add_argument(
        "--config-path",
        "-c",
        required=True,
        help="è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆwork_dir/config.pyï¼‰",
    )
    infer_parser.add_argument(
        "--output",
        "-o",
        help="çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆdefault: ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª/inference_resultsï¼‰",
    )

    args = parser.parse_args()

    if args.command == "train":
        train_command(args)
    elif args.command == "infer":
        infer_command(args)
    else:
        parser.print_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
